{
 "cells": [
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然語言處理 HW1 \n",
    "# 組員 : 110590450 歐佳昀 110590452 莊于潔\n",
    "110590450 歐佳昀(70%) : 作業架構、流程、分析、改善\n",
    "\n",
    "110590452 莊于潔(30%) : 作業模型挑選、參數調整\n",
    "\n",
    "## due 4/29,2024\n",
    "\n",
    "- Goal: Deriving word embeddings for estimating word similarity and analogy prediction on open datasets\n",
    "\n",
    "- Input: \n",
    "    - Word embeddings: fine-tuning pretrained models, or trained on your own \n",
    "    - Text dataset\n",
    "\n",
    "- Output: Result of word similarity and analogy prediction\n",
    "\n",
    "### Tasks\n",
    "\n",
    "- Deriving word embeddings for estimating word similarity and analogy prediction on open data (as detailed in the following slides)\n",
    "\n",
    "    - (40pt) (1) Deriving a word embedding model,Either fine-tuning a pretrained model Or training a new model\n",
    "    - (30pt) (2) Using word embedding for word similarity estimation\n",
    "    - (30pt) (3) Using word embedding for analogy prediction\n",
    "    - [Optional]:\n",
    "         - (25pt) (4) Compare with other document similarity estimation methods,For example, co-occurrence matrix with TF-IDF, SVD, …\n",
    "        - (25pt) (5) Apply word embeddings in other tasks,For example, classification, NER, …\n",
    "\n",
    "### Data: \n",
    "- [WordSimilarity-353 Corpus] by Evgeniy Gabrilovich Available at: https://gabrilovich.com/resources/data/wordsim353/wordsim353.html Two sets of word pairs with their similarity scores\n",
    "\n",
    "- [Bigger Analogy Test Set (BATS)] by Vecto team Available at: http://vecto.space/projects/BATS/  98,000 questions in 40 morphological and semantic categories\n",
    "\n",
    "以上資料集請放置於data/\n",
    "\n",
    "### File tree\n",
    "![image-2.png](attachment:image-2.png)\n",
    "### ref:\n",
    " - https://zhuanlan.zhihu.com/p/57765947\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Output format: \n",
    "\n",
    "#### Task 1 : \n",
    "\n",
    "word embeding :\n",
    " - wrod2vec\n",
    " - https://github.com/mmihaltz/word2vec-GoogleNews-vectors/blob/master/README.md\n",
    " - https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    " - GLoVe\n",
    " - https://github.com/stanfordnlp/GloVe\n",
    " - https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\n",
    "\n",
    " - SVD\n",
    " - https://github.com/valentinp72/svd2vec\n",
    " - ```\n",
    "    wget http://mattmahoney.net/dc/text8.zip -O text8.gz\n",
    "    gzip -d text8.gz -f\n",
    "   ```\n",
    "#### Task 2 : \n",
    "\n",
    " - (1)\n",
    "\n",
    "    model name : word2vec\n",
    "    \n",
    "    diff_abs 平均值： 1.3917418687971976\n",
    "    \n",
    "    SignificanceResult(statistic=0.6845969668422078, pvalue=1.016190193647808e-49)\n",
    "   \n",
    "   => 強相關\n",
    "\n",
    " - (2)\n",
    " \n",
    "    model name : GLoVe\n",
    "\n",
    "    diff_abs 平均值： 1.4636849824143916\n",
    "    \n",
    "    SignificanceResult(statistic=0.5987723194963509, pvalue=1.0213953289911825e-35)\n",
    "    \n",
    "    => 中等強相關(近強相關)\n",
    "\n",
    "#### Task 3 :\n",
    "\n",
    "(節選 1-3表現最好者)\n",
    "\n",
    " - (1)\n",
    "\n",
    "   model name : GLoVe\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [noun - plural_reg]\\\n",
    "   total accuracy  -  total: 35 ps: 35 lm: 35 data: 50\\\n",
    "   total: 0.7\\\n",
    "   Stemming: 0.7\\\n",
    "   Lemmatization: 0.7\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [verb_ving - ved]\\\n",
    "   total accuracy  -  total: 38 ps: 41 lm: 38 data: 50\\\n",
    "   total: 0.76\\\n",
    "   Stemming: 0.82\\\n",
    "   Lemmatization: 0.76\n",
    "\n",
    "   data/BATS\\3_Encyclopedic_semantics: category  [country - capital]\\\n",
    "   total accuracy  -  total: 46 ps: 43 lm: 46 data: 50\\\n",
    "   total: 0.92\\\n",
    "   Stemming: 0.86\\\n",
    "   Lemmatization: 0.92\n",
    "\n",
    "\n",
    " - (2)\n",
    "\n",
    "   model name : word2vec\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [noun - plural_reg]\\\n",
    "   total accuracy  -  total: 32 ps: 35 lm: 32 data: 50\\\n",
    "   total: 0.64\\\n",
    "   Stemming: 0.7\\\n",
    "   Lemmatization: 0.64\\\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [verb_ving - ved]\\\n",
    "   total accuracy  -  total: 38 ps: 43 lm: 38 data: 50\\\n",
    "   total: 0.76\\\n",
    "   Stemming: 0.86\\\n",
    "   Lemmatization: 0.76\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [verb_3psg - ved]\\\n",
    "   total accuracy  -  total: 27 ps: 30 lm: 27 data: 50\\\n",
    "   total: 0.54\\\n",
    "   Stemming: 0.6\\\n",
    "   Lemmatization: 0.54\n",
    "\n",
    " - (3)\n",
    "\n",
    "   model name : SVD - word2vec\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [noun - plural_reg]\\\n",
    "   total accuracy  -  total: 11 ps: 11 lm: 11 data: 50\\\n",
    "   total: 0.22\\\n",
    "   Stemming: 0.22\\\n",
    "   Lemmatization: 0.22\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [noun - plural_irreg]\\\n",
    "   total accuracy  -  total: 7 ps: 7 lm: 0 data: 50\\\n",
    "   total: 0.14\\\n",
    "   Stemming: 0.14\\\n",
    "   Lemmatization: 0.0\n",
    "\n",
    "   data/BATS\\1_Inflectional_morphology: category  [verb_inf - 3psg]\\\n",
    "   total accuracy  -  total: 3 ps: 7 lm: 3 data: 50\\\n",
    "   total: 0.06\\\n",
    "   Stemming: 0.14\\\n",
    "   Lemmatization: 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  - 2\n",
    " \n",
    "##### Using word embedding for word similarity estimation\n",
    "\n",
    "其中\n",
    "SignificanceResult(statistic, pvalue)\n",
    "\n",
    "statistic 表 : \n",
    "\n",
    "0.8-1.0：極強相關\n",
    "\n",
    "0.6-0.8：強相關\n",
    "\n",
    "0.4-0.6：中等強度相關\n",
    "\n",
    "0.2-0.4：弱相關\n",
    "\n",
    "0.0-0.2：極弱或者無相關"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from scipy.stats import spearmanr as sp\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入dataset (Word353) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word353 = pd.read_csv(\"data/WordSimilarity/combined.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將詞前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# ps = PorterStemmer()# 效果不好\n",
    "\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "def process_word(x):\n",
    "    if isinstance(x, str):\n",
    "        x = x.lower()\n",
    "        # x = ps.stem(x)\n",
    "        x = lm.lemmatize(x)\n",
    "    return x\n",
    "\n",
    "Word353 = Word353.applymap(process_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以word2vec對每行的兩個word預測相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(row,model):\n",
    "    if row['Word 1'] in model.key_to_index and row['Word 2']  in model.key_to_index:\n",
    "\n",
    "        return  (model.similarity(row['Word 1'], row['Word 2'])+1)*5 \n",
    "    \n",
    "    else:\n",
    "        return -5\n",
    "\n",
    "def extract_words_origin(row,model):\n",
    "    if row['Word 1'] in model.key_to_index and row['Word 2']  in model.key_to_index:\n",
    "\n",
    "        return  (model.similarity(row['Word 1'], row['Word 2'])) \n",
    "    else:\n",
    "        \n",
    "        return -5\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計算與人類 Human (mean)的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_difference(row):\n",
    "    return abs(row['model_score'] - row['Human (mean)'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入pre-train model\n",
    "\n",
    "(https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g)\n",
    "\n",
    "(需下載至本地，創建/model資料夾)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = KeyedVectors.load_word2vec_format('model/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     origin_score  model_score        Word 1    Word 2  Human (mean)  \\\n",
      "0        0.263938     6.319689          love       sex          6.77   \n",
      "1        0.517296     7.586481         tiger       cat          7.35   \n",
      "2        1.000000    10.000000         tiger     tiger         10.00   \n",
      "3        0.363463     6.817313          book     paper          7.46   \n",
      "4        0.396392     6.981958      computer  keyboard          7.62   \n",
      "..            ...          ...           ...       ...           ...   \n",
      "345      0.129479     5.647397        shower     flood          6.03   \n",
      "346      0.362721     6.813604       weather  forecast          8.34   \n",
      "347      0.145228     5.726142      disaster      area          6.25   \n",
      "348      0.296636     6.483178      governor    office          6.34   \n",
      "349      0.143093     5.715467  architecture   century          3.78   \n",
      "\n",
      "         diff_abs  \n",
      "0    4.503114e-01  \n",
      "1    2.364810e-01  \n",
      "2    2.980232e-07  \n",
      "3    6.426870e-01  \n",
      "4    6.380418e-01  \n",
      "..            ...  \n",
      "345  3.826033e-01  \n",
      "346  1.526396e+00  \n",
      "347  5.238584e-01  \n",
      "348  1.431778e-01  \n",
      "349  1.935467e+00  \n",
      "\n",
      "[350 rows x 6 columns]\n",
      "model name : word2vec\n",
      "diff_abs 平均值： 1.3917418687971976\n",
      "SignificanceResult(statistic=0.6845969668422078, pvalue=1.016190193647808e-49)\n"
     ]
    }
   ],
   "source": [
    "df = Word353.apply(extract_words,model=model_word2vec, axis=1)\n",
    "\n",
    "merge_df = pd.concat([df, Word353], axis=1)\n",
    "merge_df = merge_df.rename(columns={0: 'model_score'})\n",
    "\n",
    "df = Word353.apply(extract_words_origin,model=model_word2vec, axis=1)\n",
    "merge_df = pd.concat([df, merge_df], axis=1)\n",
    "merge_df = merge_df.rename(columns={0: 'origin_score'})\n",
    "\n",
    "\n",
    "merge_df = merge_df.drop(merge_df[merge_df['origin_score'] == -5].index)\n",
    "merge_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merge_df['diff_abs'] = merge_df.apply(calculate_difference, axis=1)\n",
    "\n",
    "print(merge_df)\n",
    "diff_abs_mean = merge_df['diff_abs'].mean()\n",
    "print(\"model name : word2vec\")\n",
    "print(\"diff_abs 平均值：\", diff_abs_mean)\n",
    "print(sp(merge_df['origin_score'],merge_df['Human (mean)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做成csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_df.to_csv(\"result/word2vec_353_wor2vec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 GLoVe\n",
    "\n",
    "pre-train model : \n",
    "(https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip)\n",
    "\n",
    "解壓縮後，載入的是glove.6B.300d.txt，需創建/model，並放入該目錄底下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glove = gensim.models.KeyedVectors.load_word2vec_format('model/glove.6B.300d.txt', no_header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word353 = Word353.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     origin_score  model_score        Word 1    Word 2  Human (mean)  diff_abs\n",
      "0        0.428830     7.144149          love       sex          6.77  0.374149\n",
      "1        0.312891     6.564454         tiger       cat          7.35  0.785546\n",
      "2        1.000000    10.000000         tiger     tiger         10.00  0.000000\n",
      "3        0.454216     7.271080          book     paper          7.46  0.188920\n",
      "4        0.441461     7.207306      computer  keyboard          7.62  0.412694\n",
      "..            ...          ...           ...       ...           ...       ...\n",
      "348      0.072899     5.364494        shower     flood          6.03  0.665506\n",
      "349      0.496258     7.481290       weather  forecast          8.34  0.858710\n",
      "350      0.261253     6.306264      disaster      area          6.25  0.056264\n",
      "351      0.404522     7.022609      governor    office          6.34  0.682609\n",
      "352      0.420720     7.103602  architecture   century          3.78  3.323602\n",
      "\n",
      "[353 rows x 6 columns]\n",
      "model name : GLoVe\n",
      "diff_abs 平均值： 1.4636849824143916\n",
      "SignificanceResult(statistic=0.5987723194963509, pvalue=1.0213953289911825e-35)\n"
     ]
    }
   ],
   "source": [
    "df = Word353.apply(extract_words,model=model_glove, axis=1)\n",
    "\n",
    "merge_df = pd.concat([df, Word353], axis=1)\n",
    "merge_df = merge_df.rename(columns={0: 'model_score'})\n",
    "\n",
    "df = Word353.apply(extract_words_origin,model=model_glove, axis=1)\n",
    "merge_df = pd.concat([df, merge_df], axis=1)\n",
    "merge_df = merge_df.rename(columns={0: 'origin_score'})\n",
    "\n",
    "\n",
    "merge_df = merge_df.drop(merge_df[merge_df['origin_score'] == -5].index)\n",
    "merge_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merge_df['diff_abs'] = merge_df.apply(calculate_difference, axis=1)\n",
    "\n",
    "print(merge_df)\n",
    "diff_abs_mean = merge_df['diff_abs'].mean()\n",
    "print(\"model name : GLoVe\")\n",
    "print(\"diff_abs 平均值：\", diff_abs_mean)\n",
    "print(sp(merge_df['origin_score'],merge_df['Human (mean)']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做成csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_df.to_csv(\"result/glove_353.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task  - 3 \n",
    "\n",
    "with [optional]\n",
    " \n",
    "##### Using word embedding for word similarity estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr as sp\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入PorterStemmer、WordNetLemmatizer模型做詞性還原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemmer\n",
    "ps=PorterStemmer()\n",
    "#Lemmatizer\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍歷各群，進行計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_files_and_folders(directory):\n",
    "    \n",
    "    arr = []\n",
    "    dic = []\n",
    "    for item in os.listdir(directory):\n",
    "        # 獲取完整的路径\n",
    "        item_path = os.path.join(directory, item)\n",
    "        dic.append(item_path)\n",
    "        _arr = []\n",
    "        for  i in  os.listdir(item_path):\n",
    "            _arr.append(i)\n",
    "        arr.append(_arr)\n",
    "        # print(arr)\n",
    "    return arr,dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word pre-process\n",
    "\n",
    "(全替換小寫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(word_txt):\n",
    "    matches = re.findall(r'\\[(.*?)\\]', word_txt)\n",
    "    parts = []\n",
    "    for match in matches:\n",
    "        if \"+\" in match:\n",
    "            parts = match.split('+')\n",
    "        else:\n",
    "            parts = match.split(' - ')\n",
    "    word1 = parts[0].lower()\n",
    "    word2 = parts[1].lower()\n",
    "    return word1, word2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新group 詞類(更換不存在的類名)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def glove_process_words(word1, word2):\n",
    "    \n",
    "    if word1 == \"verb_inf\":\n",
    "        word1 = \"verb\"\n",
    "        \n",
    "    if word1 == \"verb_ving\":\n",
    "        word1 = \"ving\"\n",
    "        \n",
    "    if word1 == \"adj\":\n",
    "        word1 = \"adjectives\"\n",
    "        \n",
    "    if word2 == \"comparative\":\n",
    "        word2 = \"er\"\n",
    "        \n",
    "    if word1 == \"verb_3psg\":\n",
    "        word1 = \"verbs\"\n",
    "        \n",
    "    if word1 == \"un\":\n",
    "        word1 = \"prefix\"\n",
    "    \n",
    "    if word2 == \"3psg\":\n",
    "        word2 = \"verbs\"\n",
    "    \n",
    "    if word2 == \"less_reg\" :\n",
    "        word2 = \"less\"\n",
    "        \n",
    "    if word2 == \"ly_reg\" :\n",
    "        word2 = \"adverb\"\n",
    "        \n",
    "    if word2 == \"adj_reg\" :\n",
    "        word2 = \"adjectives\"\n",
    "    \n",
    "    if word2 == \"verb_reg\" :\n",
    "        word2 = \"verb_reg\"\n",
    "    \n",
    "    if word2 == \"ness_reg\" :\n",
    "        word2 = \"ness\"\n",
    "    \n",
    "    if word2 == \"able_reg\" :\n",
    "        word2 = \"able\"\n",
    "    \n",
    "    if word2 == \"er_irreg\" :\n",
    "        word2 = \"er\"\n",
    "        \n",
    "    if word2 == \"tion_irreg\" :\n",
    "        word2 = \"tion\"\n",
    "        \n",
    "    if word2 == \"ment_irreg\" :\n",
    "        word2 = \"ment\"\n",
    "        \n",
    "    if word2 == \"verb_reg\" :\n",
    "        word2 = \"verb\"\n",
    "        \n",
    "    if word2 == \"plural_reg\" or word2 == \"plural_irreg\" :\n",
    "        word2 = \"plural\"\n",
    "        \n",
    "    return word1, word2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詞類預測(兩種不同情況)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(row, word1, word2, ps_total_true, lm_total_true, total_true,model):\n",
    "    guss_group = []\n",
    "    if row[word1] in model.key_to_index and word1 in model.key_to_index and word2 in model.key_to_index:\n",
    "        guss_group_cab = model.most_similar(positive=[row[word1],word1], negative=[word2], topn=1)[0][0]\n",
    "        \n",
    "        # guss_group = model_glove.most_similar(positive=[\"ankara\",\"country\"], negative=[\"capital\"], topn=5)\n",
    "        # ca b guss_group\n",
    "        \n",
    "        # a:b :: c : guss_group\n",
    "        \n",
    "        # 男人:女人::國王:??\n",
    "        # most_similar (正= [ '女人' ,  '國王' ], 負= [ '男人' ])\n",
    "        # ba c \n",
    "        guss_group_bca = model.most_similar(positive=[ word2,row[word1]], negative=[word1], topn=1)[0][0]\n",
    "        \n",
    "        if ps.stem(guss_group_cab) in row[word2] or ps.stem(guss_group_bca) in row[word2]:\n",
    "            ps_total_true += 1\n",
    "        if lm.lemmatize(guss_group_cab) in row[word2] or lm.lemmatize(guss_group_bca) in row[word2]:\n",
    "            lm_total_true += 1\n",
    "        if guss_group_cab in row[word2] or guss_group_bca in row[word2]:\n",
    "            total_true += 1\n",
    "        guss_group.append([guss_group_cab,guss_group_bca])\n",
    "    return guss_group,ps_total_true, lm_total_true, total_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "輸出format(正確率計算)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printf_results(word_pred, k, word1, word2, dic, ps_total_true, lm_total_true, total_true, total_data, f,model_name):\n",
    "   \n",
    "    # word_pred.to_csv(\"result_\"+model_name+\"/category\" + str(k + 1) + \"/\" + word1 + \"-\" + word2 + \".csv\")\n",
    "    # print(dic[k], \": \", \"category  [\", word1 + \" - \" + word2 + \" ]\")\n",
    "    # print(\"total accuracy  \", \"total : \", total_true, \"ps : \", ps_total_true, \"lm : \", lm_total_true,\"data : \",total_data)\n",
    "    # print(f'total :{(total_true ) / total_data}')\n",
    "    # print(f'Stemming  :{(ps_total_true) / total_data}')\n",
    "    # print(f'lemmatization  : {(lm_total_true) / total_data}')\n",
    "    # print()\n",
    "    \n",
    "    f.write(dic[k] + \": category  [\" + word1 + \" - \" + word2 + \"]\\n\")\n",
    "    f.write(\"total accuracy  - \" +\" total: \" + str(total_true) +\" ps: \"+str(ps_total_true) + \" lm: \" + str(lm_total_true) + \" data: \" + str(total_data) + \"\\n\")\n",
    "    f.write(f'total: {(total_true)/ total_data}\\n')\n",
    "    f.write(f'Stemming: {(ps_total_true)/ total_data}\\n')\n",
    "    f.write(f'Lemmatization: {(lm_total_true) / total_data}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入預訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_glove = gensim.models.KeyedVectors.load_word2vec_format('model/glove.6B.300d.txt', no_header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun plural_reg noun plural_reg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/BATS\\1_Inflectional_morphology :  category  [ noun - plural_reg ]\n",
      "total accuracy   total :  35 ps :  35 lm :  35 data :  50\n",
      "total :0.7\n",
      "Stemming  :0.7\n",
      "lemmatization  : 0.7\n",
      "\n",
      "noun plural_irreg noun plural_irreg\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ noun - plural_irreg ]\n",
      "total accuracy   total :  29 ps :  33 lm :  5 data :  50\n",
      "total :0.58\n",
      "Stemming  :0.66\n",
      "lemmatization  : 0.1\n",
      "\n",
      "adj comparative adj comparative\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ adj - comparative ]\n",
      "total accuracy   total :  6 ps :  6 lm :  6 data :  50\n",
      "total :0.12\n",
      "Stemming  :0.12\n",
      "lemmatization  : 0.12\n",
      "\n",
      "adj superlative adj superlative\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ adj - superlative ]\n",
      "total accuracy   total :  1 ps :  1 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "verb_inf 3psg verb_inf 3psg\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - 3psg ]\n",
      "total accuracy   total :  16 ps :  45 lm :  16 data :  50\n",
      "total :0.32\n",
      "Stemming  :0.9\n",
      "lemmatization  : 0.32\n",
      "\n",
      "verb_inf ving verb_inf ving\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - ving ]\n",
      "total accuracy   total :  18 ps :  30 lm :  18 data :  50\n",
      "total :0.36\n",
      "Stemming  :0.6\n",
      "lemmatization  : 0.36\n",
      "\n",
      "verb_inf ved verb_inf ved\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - ved ]\n",
      "total accuracy   total :  14 ps :  35 lm :  14 data :  50\n",
      "total :0.28\n",
      "Stemming  :0.7\n",
      "lemmatization  : 0.28\n",
      "\n",
      "verb_ving 3psg verb_ving 3psg\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_ving - 3psg ]\n",
      "total accuracy   total :  25 ps :  34 lm :  25 data :  50\n",
      "total :0.5\n",
      "Stemming  :0.68\n",
      "lemmatization  : 0.5\n",
      "\n",
      "verb_ving ved verb_ving ved\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_ving - ved ]\n",
      "total accuracy   total :  38 ps :  41 lm :  38 data :  50\n",
      "total :0.76\n",
      "Stemming  :0.82\n",
      "lemmatization  : 0.76\n",
      "\n",
      "verb_3psg ved verb_3psg ved\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_3psg - ved ]\n",
      "total accuracy   total :  23 ps :  23 lm :  23 data :  50\n",
      "total :0.46\n",
      "Stemming  :0.46\n",
      "lemmatization  : 0.46\n",
      "\n",
      "noun less_reg noun less_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ noun - less_reg ]\n",
      "total accuracy   total :  1 ps :  3 lm :  3 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.06\n",
      "lemmatization  : 0.06\n",
      "\n",
      "un adj_reg un adj_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ un - adj_reg ]\n",
      "total accuracy   total :  18 ps :  28 lm :  18 data :  50\n",
      "total :0.36\n",
      "Stemming  :0.56\n",
      "lemmatization  : 0.36\n",
      "\n",
      "adj ly_reg adj ly_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ adj - ly_reg ]\n",
      "total accuracy   total :  9 ps :  14 lm :  10 data :  50\n",
      "total :0.18\n",
      "Stemming  :0.28\n",
      "lemmatization  : 0.2\n",
      "\n",
      "over adj_reg over adj_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ over - adj_reg ]\n",
      "total accuracy   total :  4 ps :  8 lm :  5 data :  50\n",
      "total :0.08\n",
      "Stemming  :0.16\n",
      "lemmatization  : 0.1\n",
      "\n",
      "adj ness_reg adj ness_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ adj - ness_reg ]\n",
      "total accuracy   total :  3 ps :  8 lm :  3 data :  50\n",
      "total :0.06\n",
      "Stemming  :0.16\n",
      "lemmatization  : 0.06\n",
      "\n",
      "re verb_reg re verb_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ re - verb_reg ]\n",
      "total accuracy   total :  2 ps :  21 lm :  2 data :  50\n",
      "total :0.04\n",
      "Stemming  :0.42\n",
      "lemmatization  : 0.04\n",
      "\n",
      "verb able_reg verb able_reg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - able_reg ]\n",
      "total accuracy   total :  0 ps :  2 lm :  0 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.04\n",
      "lemmatization  : 0.0\n",
      "\n",
      "verb er_irreg verb er_irreg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - er_irreg ]\n",
      "total accuracy   total :  1 ps :  32 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.64\n",
      "lemmatization  : 0.02\n",
      "\n",
      "verb tion_irreg verb tion_irreg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - tion_irreg ]\n",
      "total accuracy   total :  0 ps :  31 lm :  0 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.62\n",
      "lemmatization  : 0.0\n",
      "\n",
      "verb ment_irreg verb ment_irreg\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - ment_irreg ]\n",
      "total accuracy   total :  1 ps :  33 lm :  2 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.66\n",
      "lemmatization  : 0.04\n",
      "\n",
      "country capital country capital\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ country - capital ]\n",
      "total accuracy   total :  46 ps :  43 lm :  46 data :  50\n",
      "total :0.92\n",
      "Stemming  :0.86\n",
      "lemmatization  : 0.92\n",
      "\n",
      "country language country language\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ country - language ]\n",
      "total accuracy   total :  13 ps :  13 lm :  13 data :  50\n",
      "total :0.26\n",
      "Stemming  :0.26\n",
      "lemmatization  : 0.26\n",
      "\n",
      "uk_city county uk_city county\n",
      "name nationality name nationality\n",
      "name occupation name occupation\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ name - occupation ]\n",
      "total accuracy   total :  1 ps :  1 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "animal young animal young\n",
      "animal sound animal sound\n",
      "animal shelter animal shelter\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ animal - shelter ]\n",
      "total accuracy   total :  1 ps :  3 lm :  3 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.06\n",
      "lemmatization  : 0.06\n",
      "\n",
      "things color things color\n",
      "male female male female\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ male - female ]\n",
      "total accuracy   total :  15 ps :  18 lm :  17 data :  50\n",
      "total :0.3\n",
      "Stemming  :0.36\n",
      "lemmatization  : 0.34\n",
      "\n",
      "hypernyms animals hypernyms animals\n",
      "hypernyms misc hypernyms misc\n",
      "hyponyms misc hyponyms misc\n",
      "meronyms substance meronyms substance\n",
      "meronyms member meronyms member\n",
      "meronyms part meronyms part\n",
      "synonyms intensity synonyms intensity\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ synonyms - intensity ]\n",
      "total accuracy   total :  6 ps :  6 lm :  6 data :  50\n",
      "total :0.12\n",
      "Stemming  :0.12\n",
      "lemmatization  : 0.12\n",
      "\n",
      "synonyms exact synonyms exact\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ synonyms - exact ]\n",
      "total accuracy   total :  8 ps :  11 lm :  10 data :  50\n",
      "total :0.16\n",
      "Stemming  :0.22\n",
      "lemmatization  : 0.2\n",
      "\n",
      "antonyms gradable antonyms gradable\n",
      "antonyms binary antonyms binary\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ antonyms - binary ]\n",
      "total accuracy   total :  13 ps :  13 lm :  13 data :  50\n",
      "total :0.26\n",
      "Stemming  :0.26\n",
      "lemmatization  : 0.26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = \"data/BATS\"\n",
    "arr,dic = list_files_and_folders(directory_path)\n",
    "\n",
    "\n",
    "with open(\"result/all_result_glove.txt\", \"w\") as f:\n",
    "    k = 0\n",
    "    for i in arr:\n",
    "        for word_txt in i:\n",
    "            \n",
    "            other = ''\n",
    "            \n",
    "            word1, word2 = extract_words(word_txt)\n",
    "            \n",
    "            word1_name = word1\n",
    "            word2_name = word2\n",
    "            \n",
    "            print(word1,word2,word1_name,word2_name)\n",
    "            \n",
    "            word1, word2 = glove_process_words(word1, word2)\n",
    "            \n",
    "            word = pd.read_csv(dic[k]+\"/\"+word_txt,sep=\"\\t\", names=[word1,word2], header=None)\n",
    "            \n",
    "            ps_total_true =0 \n",
    "            lm_total_true =0 \n",
    "            total_true =0 \n",
    "            total_data = 0\n",
    "            \n",
    "            def category_most_similar(row) :\n",
    "                global ps_total_true,lm_total_true,total_true,total_data\n",
    "                total_data +=1\n",
    "\n",
    "                guss_group,ps_total_true, lm_total_true, total_true = calculate_similarity(row, word1, word2, ps_total_true, lm_total_true, total_true,model_glove)\n",
    "                return guss_group\n",
    "\n",
    "            word_category = word.apply(category_most_similar,axis=1)\n",
    "\n",
    "            word_pred = pd.concat([word, word_category], axis=1)\n",
    "            word_pred = word_pred.rename(columns={0:\"pred\"})\n",
    "            \n",
    "            if(total_true != 0 or ps_total_true != 0 or lm_total_true != 0 ):\n",
    "                printf_results(word_pred, k, word1_name, word2_name, dic, ps_total_true, lm_total_true, total_true, total_data, f,\"glove\")\n",
    "\n",
    "\n",
    "        k+=1\n",
    "        \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入word2vec模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = KeyedVectors.load_word2vec_format('model/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "進行預測等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/BATS\\1_Inflectional_morphology :  category  [ noun - plural_reg ]\n",
      "total accuracy   total :  32 ps :  35 lm :  32 data :  50\n",
      "total :0.64\n",
      "Stemming  :0.7\n",
      "lemmatization  : 0.64\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ noun - plural_irreg ]\n",
      "total accuracy   total :  22 ps :  33 lm :  4 data :  50\n",
      "total :0.44\n",
      "Stemming  :0.66\n",
      "lemmatization  : 0.08\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ adj - comparative ]\n",
      "total accuracy   total :  11 ps :  13 lm :  11 data :  50\n",
      "total :0.22\n",
      "Stemming  :0.26\n",
      "lemmatization  : 0.22\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ adj - superlative ]\n",
      "total accuracy   total :  1 ps :  3 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.06\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - 3psg ]\n",
      "total accuracy   total :  12 ps :  38 lm :  12 data :  50\n",
      "total :0.24\n",
      "Stemming  :0.76\n",
      "lemmatization  : 0.24\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - ving ]\n",
      "total accuracy   total :  26 ps :  38 lm :  27 data :  50\n",
      "total :0.52\n",
      "Stemming  :0.76\n",
      "lemmatization  : 0.54\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - ved ]\n",
      "total accuracy   total :  17 ps :  39 lm :  17 data :  50\n",
      "total :0.34\n",
      "Stemming  :0.78\n",
      "lemmatization  : 0.34\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_ving - 3psg ]\n",
      "total accuracy   total :  23 ps :  42 lm :  24 data :  50\n",
      "total :0.46\n",
      "Stemming  :0.84\n",
      "lemmatization  : 0.48\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_ving - ved ]\n",
      "total accuracy   total :  38 ps :  43 lm :  38 data :  50\n",
      "total :0.76\n",
      "Stemming  :0.86\n",
      "lemmatization  : 0.76\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_3psg - ved ]\n",
      "total accuracy   total :  27 ps :  30 lm :  27 data :  50\n",
      "total :0.54\n",
      "Stemming  :0.6\n",
      "lemmatization  : 0.54\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ noun - less_reg ]\n",
      "total accuracy   total :  0 ps :  13 lm :  10 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.26\n",
      "lemmatization  : 0.2\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ un - adj_reg ]\n",
      "total accuracy   total :  9 ps :  27 lm :  10 data :  50\n",
      "total :0.18\n",
      "Stemming  :0.54\n",
      "lemmatization  : 0.2\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ adj - ly_reg ]\n",
      "total accuracy   total :  5 ps :  24 lm :  6 data :  50\n",
      "total :0.1\n",
      "Stemming  :0.48\n",
      "lemmatization  : 0.12\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ over - adj_reg ]\n",
      "total accuracy   total :  4 ps :  21 lm :  4 data :  50\n",
      "total :0.08\n",
      "Stemming  :0.42\n",
      "lemmatization  : 0.08\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ adj - ness_reg ]\n",
      "total accuracy   total :  7 ps :  25 lm :  7 data :  50\n",
      "total :0.14\n",
      "Stemming  :0.5\n",
      "lemmatization  : 0.14\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ re - verb_reg ]\n",
      "total accuracy   total :  5 ps :  32 lm :  5 data :  50\n",
      "total :0.1\n",
      "Stemming  :0.64\n",
      "lemmatization  : 0.1\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - able_reg ]\n",
      "total accuracy   total :  0 ps :  29 lm :  0 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.58\n",
      "lemmatization  : 0.0\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - er_irreg ]\n",
      "total accuracy   total :  1 ps :  41 lm :  2 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.82\n",
      "lemmatization  : 0.04\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - tion_irreg ]\n",
      "total accuracy   total :  5 ps :  43 lm :  5 data :  50\n",
      "total :0.1\n",
      "Stemming  :0.86\n",
      "lemmatization  : 0.1\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ verb - ment_irreg ]\n",
      "total accuracy   total :  4 ps :  41 lm :  4 data :  50\n",
      "total :0.08\n",
      "Stemming  :0.82\n",
      "lemmatization  : 0.08\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ country - capital ]\n",
      "total accuracy   total :  8 ps :  8 lm :  8 data :  50\n",
      "total :0.16\n",
      "Stemming  :0.16\n",
      "lemmatization  : 0.16\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ country - language ]\n",
      "total accuracy   total :  2 ps :  2 lm :  2 data :  50\n",
      "total :0.04\n",
      "Stemming  :0.04\n",
      "lemmatization  : 0.04\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ animal - young ]\n",
      "total accuracy   total :  0 ps :  1 lm :  1 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ animal - shelter ]\n",
      "total accuracy   total :  2 ps :  3 lm :  3 data :  50\n",
      "total :0.04\n",
      "Stemming  :0.06\n",
      "lemmatization  : 0.06\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ male - female ]\n",
      "total accuracy   total :  16 ps :  21 lm :  20 data :  50\n",
      "total :0.32\n",
      "Stemming  :0.42\n",
      "lemmatization  : 0.4\n",
      "\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ synonyms - intensity ]\n",
      "total accuracy   total :  9 ps :  9 lm :  9 data :  50\n",
      "total :0.18\n",
      "Stemming  :0.18\n",
      "lemmatization  : 0.18\n",
      "\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ synonyms - exact ]\n",
      "total accuracy   total :  14 ps :  17 lm :  16 data :  50\n",
      "total :0.28\n",
      "Stemming  :0.34\n",
      "lemmatization  : 0.32\n",
      "\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ antonyms - gradable ]\n",
      "total accuracy   total :  11 ps :  14 lm :  11 data :  50\n",
      "total :0.22\n",
      "Stemming  :0.28\n",
      "lemmatization  : 0.22\n",
      "\n",
      "data/BATS\\4_Lexicographic_semantics :  category  [ antonyms - binary ]\n",
      "total accuracy   total :  17 ps :  17 lm :  17 data :  50\n",
      "total :0.34\n",
      "Stemming  :0.34\n",
      "lemmatization  : 0.34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = \"data/BATS\"\n",
    "arr,dic = list_files_and_folders(directory_path)\n",
    "\n",
    "\n",
    "with open(\"result/all_result_word2vec.txt\", \"w\") as f:\n",
    "    k = 0\n",
    "    for i in arr:\n",
    "        for word_txt in i:\n",
    "            \n",
    "            word1, word2 = extract_words(word_txt)\n",
    "            \n",
    "            word1_name = word1\n",
    "            word2_name = word2\n",
    "            \n",
    "            word1, word2 = glove_process_words(word1, word2)\n",
    "                        \n",
    "            word = pd.read_csv(dic[k]+\"/\"+word_txt,sep=\"\\t\", names=[word1,word2], header=None)\n",
    "            \n",
    "            ps_total_true =0 \n",
    "            lm_total_true =0 \n",
    "            total_true =0 \n",
    "            total_data = 0\n",
    "            \n",
    "            def category_most_similar(row) :\n",
    "                global ps_total_true,lm_total_true,total_true,total_data\n",
    "                total_data +=1\n",
    "\n",
    "                guss_group,ps_total_true, lm_total_true, total_true = calculate_similarity(row, word1, word2, ps_total_true, lm_total_true, total_true,model_word2vec)\n",
    "                return guss_group\n",
    "\n",
    "            word_category = word.apply(category_most_similar,axis=1)\n",
    "\n",
    "            word_pred = pd.concat([word, word_category], axis=1)\n",
    "            word_pred = word_pred.rename(columns={0:\"pred\"})\n",
    "            \n",
    "            if(total_true != 0 or ps_total_true != 0 or lm_total_true != 0 ):\n",
    "                printf_results(word_pred, k, word1_name, word2_name, dic, ps_total_true, lm_total_true, total_true, total_data, f,\"word2vec\")\n",
    "\n",
    "\n",
    "        k+=1\n",
    "        \n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "載入SVD (自訓練 - SVD-wor2vec )\n",
    "\n",
    "自訓練\n",
    "\n",
    "```\n",
    "python pre_svd.py\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svd = KeyedVectors.load_word2vec_format(\"svd_word2vec_format.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "進行預測等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/BATS\\1_Inflectional_morphology :  category  [ noun - plural_reg ]\n",
      "total accuracy   total :  11 ps :  11 lm :  11 data :  50\n",
      "total :0.22\n",
      "Stemming  :0.22\n",
      "lemmatization  : 0.22\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ noun - plural_irreg ]\n",
      "total accuracy   total :  7 ps :  7 lm :  0 data :  50\n",
      "total :0.14\n",
      "Stemming  :0.14\n",
      "lemmatization  : 0.0\n",
      "\n",
      "data/BATS\\1_Inflectional_morphology :  category  [ verb_inf - 3psg ]\n",
      "total accuracy   total :  3 ps :  7 lm :  3 data :  50\n",
      "total :0.06\n",
      "Stemming  :0.14\n",
      "lemmatization  : 0.06\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ noun - less_reg ]\n",
      "total accuracy   total :  0 ps :  1 lm :  1 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ un - adj_reg ]\n",
      "total accuracy   total :  3 ps :  4 lm :  3 data :  50\n",
      "total :0.06\n",
      "Stemming  :0.08\n",
      "lemmatization  : 0.06\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ over - adj_reg ]\n",
      "total accuracy   total :  2 ps :  3 lm :  2 data :  50\n",
      "total :0.04\n",
      "Stemming  :0.06\n",
      "lemmatization  : 0.04\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ adj - ness_reg ]\n",
      "total accuracy   total :  0 ps :  1 lm :  0 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.0\n",
      "\n",
      "data/BATS\\2_Derivational_morphology :  category  [ re - verb_reg ]\n",
      "total accuracy   total :  0 ps :  2 lm :  0 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.04\n",
      "lemmatization  : 0.0\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ country - capital ]\n",
      "total accuracy   total :  1 ps :  1 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ country - language ]\n",
      "total accuracy   total :  2 ps :  2 lm :  2 data :  50\n",
      "total :0.04\n",
      "Stemming  :0.04\n",
      "lemmatization  : 0.04\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ name - nationality ]\n",
      "total accuracy   total :  0 ps :  1 lm :  1 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ name - occupation ]\n",
      "total accuracy   total :  0 ps :  1 lm :  1 data :  50\n",
      "total :0.0\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ things - color ]\n",
      "total accuracy   total :  1 ps :  1 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n",
      "data/BATS\\3_Encyclopedic_semantics :  category  [ male - female ]\n",
      "total accuracy   total :  1 ps :  1 lm :  1 data :  50\n",
      "total :0.02\n",
      "Stemming  :0.02\n",
      "lemmatization  : 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory_path = \"data/BATS\"\n",
    "arr,dic = list_files_and_folders(directory_path)\n",
    "\n",
    "\n",
    "with open(\"result/all_result_svd.txt\", \"w\") as f:\n",
    "    k = 0\n",
    "    for i in arr:\n",
    "        for word_txt in i:\n",
    "            \n",
    "            word1, word2 = extract_words(word_txt)\n",
    "            \n",
    "            word1_name = word1\n",
    "            word2_name = word2\n",
    "            \n",
    "            word1, word2 = glove_process_words(word1, word2)\n",
    "                        \n",
    "            word = pd.read_csv(dic[k]+\"/\"+word_txt,sep=\"\\t\", names=[word1,word2], header=None)\n",
    "            \n",
    "            ps_total_true =0 \n",
    "            lm_total_true =0 \n",
    "            total_true =0 \n",
    "            total_data = 0\n",
    "            \n",
    "            def category_most_similar(row) :\n",
    "                global ps_total_true,lm_total_true,total_true,total_data\n",
    "                total_data +=1\n",
    "\n",
    "                guss_group,ps_total_true, lm_total_true, total_true = calculate_similarity(row, word1, word2, ps_total_true, lm_total_true, total_true,model_svd)\n",
    "                return guss_group\n",
    "\n",
    "            word_category = word.apply(category_most_similar,axis=1)\n",
    "\n",
    "            word_pred = pd.concat([word, word_category], axis=1)\n",
    "            word_pred = word_pred.rename(columns={0:\"pred\"})\n",
    "            \n",
    "            if(total_true != 0 or ps_total_true != 0 or lm_total_true != 0 ):\n",
    "                printf_results(word_pred, k, word1_name, word2_name, dic, ps_total_true, lm_total_true, total_true, total_data, f,\"svd\")\n",
    "\n",
    "\n",
    "        k+=1\n",
    "        \n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
